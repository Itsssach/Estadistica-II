---
output: 
  stevetemplates::article:
    fig_caption: true
#bibliography: master.bib
biblio-style: apsr
title: "Taller Práctico Regresión Lineal Simple (1)"
thanks: "El material asociado a este taller puede encontrarse en el repositorio del curso, **(https://github.com/Itsssach/Estadistica-II)**"
author:
- name: Estadística II
  affiliation: Universidad Nacional de Colombia, Sede Medellín
abstract: "Este documento corresponde al primer taller práctico del curso de **Estadística II** para la *Universidad Nacional de Colombia*, Sede Medellín, en el periodo 2025 - 2. Se brinda una introducción al análisis de regresión. El enfoque de este taller está sobre las componentes asociadas al modelo de regresión lineal simple -especialmente los parámetros-. **Monitor:** *Santiago Carmona Hincapié.*"
keywords: "regresión, parámetros"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
#fontfamily: mathpazo
fontsize: 12pt
# spacing: double
endnote: no
language: "es"
header-includes:
  - \usepackage{booktabs}
---

```{r setup, include=FALSE}
# -----------------------------
if (!dir.exists("figs")) dir.create("figs")
if (!dir.exists("_cache")) dir.create("_cache")
# -----------------------------
knitr::opts_chunk$set(cache=TRUE,
                      message=FALSE, warning=FALSE,
                      fig.path='figs/',
                      cache.path = '_cache/',
                      fig.process = function(x) {
                      x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
                      if (file.rename(x, x2)) x2 else x
                      }, 
                      fig.align="center")
```

```{r, echo=FALSE}
# -----------------------------
#           Libraries
# -----------------------------
if(!require(pacman)){install.packages("pacman"); library(pacman)}
pacman::p_load("tidyverse", "knitr", "leaps","tidyr",
               "exams","leaps","MASS","rsm","car","magrittr","readxl", "kableExtra", "ggthemes")
# Para cargar librerías puede usarse la instrucción anterior, donde se
# especifica la función p_load() de la librería pacman, o bien, de
# la forma tradicional:
# library("tidyverse")
# library("knitr"), etc.
# Para este problema sólo se emplea "tidyverse" y "GGthemes" para
# personalizar con la función theme_gdocs() en las gráficas
```

```{r, echo=FALSE}
# -----------------------------
#           Read data
# -----------------------------
data <- read.csv("data/FreedomIndex.csv") |> 
  tidyr::drop_na() |> 
  dplyr::select(3:15) |> 
  dplyr::rename(OS = Overall.Score, PR = Property.Rights, 
                GI = Government.Integrity, JE = Judicial.Effectiveness, 
                TB = Tax.Burden, GS = Government.Spending, 
                FH = Fiscal.Health, BF = Business.Freedom, 
                LF = Labor.Freedom, MF = Monetary.Freedom, 
                TF = Trade.Freedom, IF = Investment.Freedom, 
                FF = Financial.Freedom)
# -----------------------------
old_names <- data.frame(old = c("Overall.Score", "Property.Rights", "Government.Integrity", "Judicial.Effectiveness", "Tax.Burden", "Government.Spending", "Fiscal.Health", "Business.Freedom", "Labor.Freedom", "Monetary.Freedom", "Trade.Freedom", "Investment.Freedom", "Financial.Freedom"), new = c("OS", "PR", "GI", "JE", "TB", "GS", "FH", "BF", "LF", "MF", "TF", "IF", "FF"))

```

# Información general

Con el propósito de profundizar en los conceptos del modelo de regresión lineal simple vistos en clase, se propone afrontar dos problemas prácticos. El segundo consta de una simulación que ahonda en las propiedades de los parámetros del modelo de regresión. El primero, es una aproximación al uso del modelo en situaciones de la vida real.

**La solución para cada uno de los problemas se efectúa a partir del software estadístico R.**

## Ejercicio con datos reales

El índice de libertad económica es una medida que *evalúa el grado de libertad económica* en diferentes países. Se presentan diversos atributos, cuya descripción puede encontrarse **en el siguiente enlace:** https://www.kaggle.com/datasets/mlippo/freedom-economic-index/data

\begin{table}[ht]
\centering
\begin{tabular}{rccccccccccccc}
\toprule
OS & PR & GI & JE & TB & GS & FH & BF & LF & MF & TF & IF & FF \\
\midrule
1 & 83.5 & 94.2 & 88.3 & 58.3 & 90.7 & 89.2 & 76.0 & 86.9 & 77.3 & 76.3 & 95.0 & 90 & 80 \\
2 & 83.0 & 94.2 & 91.3 & 98.1 & 70.4 & 64.6 & 95.7 & 89.3 & 60.7 & 80.8 & 86.4 & 85 & 80 \\
3 & 82.6 & 93.5 & 83.4 & 94.3 & 78.0 & 82.4 & 91.7 & 91.3 & 62.8 & 74.5 & 79.2 & 90 & 70 \\
4 & 80.0 & 82.2 & 73.4 & 94.0 & 79.2 & 90.5 & 90.3 & 84.9 & 69.1 & 80.1 & 86.4 & 70 & 60 \\
5 & 79.2 & 96.9 & 84.9 & 95.8 & 64.6 & 40.6 & 97.6 & 89.5 & 57.7 & 69.1 & 79.2 & 95 & 80 \\
6 & 77.8 & 98.6 & 97.4 & 89.6 & 41.8 & 26.8 & 98.2 & 92.7 & 64.9 & 74.3 & 79.2 & 90 & 80 \\
\bottomrule
\end{tabular}
\caption{Información en análisis}
\end{table}

Considere a *'Overall Score'* como la variable respuesta. *Escoja una covariable y de respuesta a los siguientes planteamientos:*

```{=tex}
\begin{enumerate}
\item Realice un \textbf{breve análisis descriptivo}. ¿Un modelo de regresión lineal simple podría ser adecuado en este caso? ¿Por qué?
\item Escriba la ecuación del modelo de regresión lineal, considerando los supuestos asociados. Obtenga los valores calculados de los parámetros, $\overline{y}, \hat{y}, \hat{\varepsilon_{i}}$ y analícelos.
\item Determine si los parámetros del modelo $\beta_{0}, \beta_{1}$ son significativos, considerando $\alpha = 0.05$. Realice una interpretación en relación al problema. \textbf{¿Estos parámetros tienen sentido?}
\item Calcule un intervalo de confianza -considerando $\alpha = 0.05$- para ambos parámetros. ¿Puede concluir a partir de este resultado si los parámetros son significativos?
\end{enumerate}
```

## Ejercicio de simulación

A partir de una simulación se pretende ilustrar algunos de los principios teóricos que comprenden el análisis de regresión lineal simple. Así, se plantea un modelo $Y_{i} = \beta_{0} + \beta_{1}X_{1i} + \varepsilon_{i}, \varepsilon_{i} \overset{\text{iid}}{\sim} N(0, \sigma^{2})$, tal que $\beta_{0} = 50, \beta_{1} = 10, \sigma^{2} = 16$. Suponga que se emplean $n = 20$ observaciones para ajustar el modelo. **Genere** $\mathbf{500}$ **muestras de** $\mathbf{20}$ **observaciones de tal manera que** $x = 1, 1.5, 2, ..., 10$ **para cada muestra.**

```{=tex}
\begin{enumerate}
\item Para cada muestra calcule $\hat{\beta_{0}}, \hat{\beta_{1}}$. Construya un histograma para cada parámetro estimado y concluya.
\item Para cada muestra, calcule un intervalo de confianza al $90\%$ para $\beta_{1}$. \textit{¿Cuántos de estos intervalos contienen al verdadero valor del parámetro? ¿Se corresponde la simulación con la teoría?}  
\end{enumerate}
```

```{=html}
<!--
# References
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\vspace*{-0.2in}
\noindent
-->
```

\newpage

# Solución

**Se brinda la solución de la simulación, como ejercicio de profundización teórico- práctica.**

## Simulación

### Primer punto

Para cada muestra calcule $\hat{\beta_{0}}, \hat{\beta_{1}}$. Construya un histograma para cada parámetro estimado y concluya.

```{r, echo=FALSE}
# --------------------------
#     Generación datos 
# --------------------------
x <- seq(1, 10, by= 0.5) # Generación datos
sigma2 <- 16 # Indicado en el modelo
nsim <- 500 # Número de simulaciones
X <- matrix(rep(x, times= nsim), byrow= TRUE, nrow= nsim) # Generación matriz
# --------------------------
#  Simulación y modelación 
# --------------------------
# Función para la estimación del modelo
simulacion <- function(x){
  n <- length(x) # Longitud del vector
  y <- 50+ 10*x+ rnorm(n, mean= 0, sd= 4) # Modelo lineal
  modelo <- lm(y ~ x) # Ajuste del modelo
  return(modelo) # Retorno de la función
} # Finalización función
# Función para el cálculo del (MSE)
MSE <- function(residual){
  mse <- sum(residual^2)/(length(residual)- 2) # Definición MSE
  return(mse) # Valor de retorno
} # Finalización función
# Función para el cálculo del SSE
SSE <- function(residual){
  sse <- sum(residual^2) # Definición SSE
  return(sse) # Valor de retorno
} # Finalización función
```

```{r, echo=FALSE}
# --------------------------
#  Simulación y modelación 
# --------------------------
# Obtención de 500 regresiones
auxiliar <- apply(X, 1, simulacion) # Aplicación simulación
# Obtención parámetros estimados de las rectas ajustadas
betas <- sapply(auxiliar, coef) # Obteniendo coeficientes
betas_0 <- betas[1, ] # Extracción
betas_1 <- betas[2, ] # Extracción 
# Obtención respuestas estimadas en cada muestra simulada
y_hats <- sapply(auxiliar, fitted) # Valores ajustados
# Obtención residuos en cada muestra simulada 
residual <- sapply(auxiliar, residuals) # Extracción
# Obtención del MSE y SSE en cada muestra simulada
mses <- apply(residual, 2, MSE) 
sses <- apply(residual, 2, SSE)
```

```{r, echo=FALSE}
# --------------------------
#  Simulación y modelación 
# --------------------------
# Obtención de sumas de cuadrados corregidos en X
Sxx <- function(x){
  n <- length(x) # Longitud
  x_bar <- mean(x) # Media
  sxx <- sum((x- x_bar)^2) # Suma de cuadrados
  return(sxx) # Valor de retorno
} # Finalización función
# Obtención Sxx para cada muestra simulada
sxx_values <- apply(X, 1, Sxx) # Generación
# Véase que la suma de cuadrados corregidos es la misma siempre
sxx <- sxx_values[[1]] # Valor específico
desviacion <- sqrt(mses/sxx) # Desviación
```

```{r, echo=FALSE}
# --------------------------
#  Intervalos de confianza 
# --------------------------
# Valor crítico con alpha= 0.1 y 17 grados de libertad
valor_critico_t <- qt(0.95, df= 17) # Cálculo
radio <- valor_critico_t*desviacion # Precisión intervalo
results <- matrix(NA, nrow= 500, ncol= 2) # Matriz vacía para el almacenamiento
# Generación de los intervalos de confianza
for (i in 1:500){ 
  lower_ci <- betas_1[i]- radio[i] # Inferior
  upper_ci <- betas_1[i]+ radio[i] # Superior
  results[i, ] <- c(lower_ci, upper_ci) # Asignación
} # Término del ciclo
# Contar cuántos intervalos incluyen el valor 10
inside_interval <- sum(10 >= results[, 1] & 10 <= results[, 2])
```

Al llevar a cabo las simulaciones requeridas en esta sección, se tiene que para el modelo de regresión lineal simple planteado como $Y_i= 50+ 10X_i + \varepsilon_i, \varepsilon_i \sim N(0, 16)$, se definió diferentes muestras -en específico, $500$ muestras- a las que se les calculó los parámetros estimados $\hat{\beta_0}$ y $\hat{\beta_1}$. Se muestra a continuación algunos de los parámetros calculados:

\usepackage{booktabs}

\begin{table}[ht]
\centering
\begin{tabular}{rr}
\toprule
Intercept & x \\
\midrule
53.5166 &  9.2950 \\
50.6157 &  9.7142 \\
45.2012 & 10.4882 \\
49.4910 & 10.2871 \\
48.1708 & 10.4587 \\
\multicolumn{2}{c}{\dots} \\
48.5891 &  9.9879 \\
47.0918 & 10.2347 \\
49.6162 &  9.9060 \\
52.5709 &  9.7982 \\
51.5690 &  9.6207 \\
\bottomrule
\end{tabular}
\caption{Coeficientes estimados para Intercept y x}
\end{table}

Para la información anterior, se muestra a continuación, los histogramas correspondientes. Se muestra en primer lugar el histograma para $\hat{\beta_0}$, luego, se mostrará el correspondiente histograma para $\hat{\beta_1}$:

```{r, echo=FALSE}
# --------------------------
#    Creación histogramas 
# --------------------------
ggplot(as.data.frame(betas_0), aes(betas_0)) + 
  geom_histogram(aes(y= after_stat(density)), fill= "lightgray",
                 color= "black", binwidth= 0.8) +
  geom_density(color= "red", lwd= 1, fill= "red", alpha= 0.5) +
  labs(title= expression(paste("Histograma de densidad ", hat(beta[0]))), 
       x= expression(paste("Valor estimaciones ", hat(beta[0]))), 
       y= "Densidad", subtitle= "En relación a las simulaciones" ) + theme_gdocs() + 
  theme(plot.title= element_text(color= "black", size= 15, face= "bold"),
  axis.title.x= element_text(color= "black", size= 12, face= "bold"),
  axis.title.y= element_text(color= "black", size= 12, face= "bold"),
  plot.subtitle= element_text(color= "gray", size= 12, face= "bold.italic"),
  axis.text.x= element_text(size= 8), 
  axis.text.y= element_text(size= 8)) +
  scale_color_brewer(palette= "Dark2") + guides(size= none, alpha= none)
```

Obsérvese que este histograma sigue una curva simétrica, asemejándose a una distribución normal. De hecho, su media está dada por $\overline{\beta_0}=$ `r mean(betas_0)`, mientras que su mediana está dada por `r median(betas_0)` -al menos el $50\%$ de los estimadores son menores o iguales al valor de la mediana especificado-, lo que indica que existe una diferencia de `r abs(median(betas_0)- mean(betas_0))`, que es una diferencia mínima, indicando la gran simetría de la distribución en cuestión. De hecho, tomando en consideración $\overline{\beta_0}=$ `r mean(betas_0)`, puede verse que los estimadores simulados, en promedio, se acercan en gran medida al valor real del parámetro $\beta_0= 50$. 

Se muestra a continuación el respectivo histograma para las simulaciones de los parámetros estimados $\hat{\beta_1}$: 

```{r, echo=FALSE}
# --------------------------
#    Creación histogramas 
# --------------------------
ggplot(as.data.frame(betas_1), aes(betas_1)) + 
  geom_histogram(aes(y= after_stat(density)), fill= "lightgray",
                 color= "black", binwidth= 0.1) +
  geom_density(color= "red", lwd= 1, fill= "red", alpha= 0.5) +
  labs(title= expression(paste("Histograma densidad ", hat(beta[1]))), 
       x= expression(paste("Valor estimaciones ", hat(beta[1]))), 
       y= "Densidad", subtitle= "En relación a las simulaciones" ) +
  # Personalización (opcional)
  theme_gdocs() + 
  theme(plot.title= element_text(color= "black", size= 15, face= "bold"),
  axis.title.x= element_text(color= "black", size= 12, face= "bold"),
  axis.title.y= element_text(color= "black", size= 12, face= "bold"),
  plot.subtitle= element_text(color= "gray", size= 12, face= "bold.italic"),
  axis.text.x= element_text(size= 8), 
  axis.text.y= element_text(size= 8)) +
  scale_color_brewer(palette= "Dark2") + guides(size= none, alpha= none)
```

Obsérvese que este histograma sigue una curva simétrica, asemejándose a una distribución normal. De hecho, su media está dada por $\overline{\beta_1}=$ `r mean(betas_1)`, mientras que su mediana está dada por `r median(betas_1)` -al menos el $50\%$ de los estimadores son menores o iguales al valor de la mediana especificado-, lo que indica que existe una diferencia de `r abs(median(betas_1)- mean(betas_1))`, que es una diferencia mínima, indicando la gran simetría de la distribución en cuestión. De hecho, tomando en consideración $\overline{\beta_1}=$ `r mean(betas_1)`, puede verse que los estimadores simulados, en promedio, se acercan en gran medida al valor real del parámetro $\beta_1= 10$.

En general, se podría generar un correcto ajuste al modelo de regresión planteado $Y_i= 50+ 10X_i + \varepsilon_i, \varepsilon_i \sim N(0, 16)$.

### Segundo punto

Para cada muestra, calcule un intervalo de confianza al $90\%$ para $\beta_{1}$. *¿Cuántos de estos intervalos contienen al verdadero valor del parámetro? ¿Se corresponde la teoría con la práctica?*

En esta sección, para cada muestra, se pretende calcular un intervalo de confianza al $90\%$ para $\beta_1$, de manera que sea posible determinar el número de intervalos de confianza acertados para cada una de las simulaciones. Es así que, se muestran los resultados obtenidos en la tabla a continuación:

\begin{table}[ht]
\centering
\begin{tabular}{ll}
\toprule
Límite inferior & Límite superior \\
\midrule
10.3008903884351 & 11.416257712071 \\
9.07599773509479 & 10.3389819845068 \\
9.53097155521358 & 10.9549732423272 \\
9.44998479707449 & 10.4277563369773 \\
9.36349216516306 & 11.1294174125507 \\
.                & .                \\
.                & .                \\
.                & .                \\
9.52675099369557 & 10.5655813816525 \\
9.47805049626882 & 10.6880826200056 \\
9.27636795158881 & 10.5059629025387 \\
9.30463581825916 & 10.7443512373935 \\
9.34602507927074 & 10.4883808975334 \\
\bottomrule
\end{tabular}
\caption{Intervalos de confianza}
\end{table}

De los cuales, fue posible determinar que exactamente `r inside_interval` intervalos contienen el verdadero valor del parámetro $\beta_1= 10$, que equivale a `r inside_interval/500`, como era de esperarse, dado el nivel de significancia especificado inicialmente de un $90\%$. **Esto permite reflejar la manera en que se acerca la teoría a la práctica.**
