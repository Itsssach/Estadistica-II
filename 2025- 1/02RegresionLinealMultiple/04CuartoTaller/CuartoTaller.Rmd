---
output: 
  stevetemplates::article:
    fig_caption: true
#bibliography: master.bib
biblio-style: apsr
title: "Taller Práctico Regresión Lineal Múltiple (4)"
thanks: "El material asociado a este taller puede encontrarse en el repositorio del curso, **(https://github.com/Itsssach/Estadistica-II)**"
author:
- name: Estadística II
  affiliation: Universidad Nacional de Colombia, Sede Medellín
abstract: "Este documento corresponde al cuarto taller práctico del curso de **Estadística II** para la *Universidad Nacional de Colombia*, Sede Medellín, en el periodo 2025 - 1. Se brinda una introducción al análisis de regresión. El enfoque de este taller está la comprensión del problema de multicolinealidad (efectos y diagnósticos), así como el método de todas regresiones posibles para la selección de variables. **Monitor:** *Santiago Carmona Hincapié.*"
keywords: "regresión múltiple, multicolinealidad, selección"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
#fontfamily: mathpazo
fontsize: 12pt
# spacing: double
endnote: no
language: "es"
header-includes:
  - \usepackage{bm}
---

```{r setup, include=FALSE}
# -----------------------------
if (!dir.exists("figs")) dir.create("figs")
if (!dir.exists("_cache")) dir.create("_cache")
# -----------------------------
knitr::opts_chunk$set(cache=TRUE,
                      message=FALSE, warning=FALSE,
                      fig.path='figs/',
                      cache.path = '_cache/',
                      fig.process = function(x) {
                      x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
                      if (file.rename(x, x2)) x2 else x
                      })
```

```{r, echo=FALSE}
# -----------------------------
#           Libraries
# -----------------------------
if(!require(pacman)){install.packages("pacman"); library(pacman)}
pacman::p_load("tidyverse", "knitr", "leaps","tidyr",
               "exams","leaps","MASS","rsm","car","magrittr",
               "readxl", "kableExtra")
```

```{r, echo=FALSE}
# -----------------------------
#           Read data
# -----------------------------
data <- read.csv("data/students_performance3.csv")
```

# Información general

Con el propósito de profundizar en los conceptos del modelo de regresión lineal múltiple vistos en clase, se propone afrontar este taller en dos partes, una de teoría básica y otra práctica.

**La solución para cada uno de los problemas se efectúa a partir del software estadístico R.**

## Parte teórica

De respuesta a las preguntas formuladas a continuación en base a la teoría tratada en clase. **Provea una interpretación de ser necesario**.

\begin{enumerate}
  \item Determine el valor de verdad de las siguientes afirmaciones.
  \begin{itemize}
    \item (a) Bajo el modelo de regresión lineal múltiple $Y_{i} = \beta_{0}+ \beta_{1}X_{i1}+ \beta_{2}X_{i2}+ ...+ \beta_{k}X_{ik}+ \varepsilon_{i}; \varepsilon_{i} \overset{iid}{\sim} N(0, \sigma^{2})$, la comparación de los efectos parciales de las variables debe realizarse a través del \textbf{escalamiento normal unitario de las covariables}.
    \item (b) La multicolinealidad refiere a la dependencia lineal casi perfecta entre covariables, afectando la matriz $\mathbf{X'X}$. Esta puede destacartarse si la correlación entre un par de variables $X_{i} \neq X_{j}$ es pequeña.
    \item (c) La multicolinealidad puede causar la inflación de las varianzas de los estimadores, además de estimadores $\hat{\beta_{j}}$ muy grandes en términos absolutos y valores de los coeficientes estimados con signo contrario a lo esperado.
    \item (d) Una forma en la que se manifiesta la multicolinealidad grave es cuando el modelo de regresión ajustado es significativo (globalmente), pero los parámetros individuales no lo son.
    \item (e) Dado que el estadístico $C_{p}$ es una medida del sesgo del modelo, se prefiere el estadístico más bajo, puesto que a mayor sesgo mayor $C_{p}$. 
    \item (f) La suma de cuadrados de los errores de predicción $e_{(i)} = Y_{i}- \hat{Y}_{i(i)}$ mide qué tan bien los valores ajustados por un submodelo predicen las respuestas observadas. \textbf{Mejor se considerará el modelo entre mayor sea esta métrica}.
  \end{itemize}
\end{enumerate}

## Ejercicio con datos reales

Considere el siguiente conjunto de datos que agrupa una serie de métricas enfocadas en evaluar el rendimiento en educación física de estudiantes en una institución. **Se incluyen únicamente las métricas cuantitativas,** cuya descripción puede encontrarse **en el siguiente enlace:** https://www.kaggle.com/datasets/ziya07/student-physical-education-performance

```{r, echo=FALSE}
table <- head(data, 5)
table |> 
  knitr::kable(booktabs= TRUE, 
  caption= "Información en análisis", 
               align= "c") |> # Kable Table
  kableExtra::kable_styling(full_width= FALSE, latex_options= 
                              "HOLD_position", font_size= 10) |> 
  kableExtra::column_spec(1, bold = TRUE) # Boldness
```

Considere a *'Overall Performance'* como la variable respuesta. *Las covariables en análisis se especifican en la tabla mostrada con anterioridad.* **Suponga que los supuestos del modelo se cumplen. De respuesta a los siguientes planteamientos:**

\begin{enumerate}
\item Escriba el modelo de regresión lineal múltiple, junto con sus supuestos. Deduzca a partir del modelo ajustado si podría haber problemas de multicolinealidad. 
\item Realice un análisis de multicolinealidad a través del criterio del factor de inflación de varianza, número de condición, índice de condición y proporción de descomposición de varianza.
\item Use el método de todas las regresiones posibles para seleccionar los mejores submodelos en función de los criterios $\text{R}^{2}_{p}, \text{R}_{adj(p)}^{2} \text{ (o bien } \text{MSE}_{p}) \text{ y } C_{p}$. \textbf{Posteriormente seleccione el mejor modelo.} 
\end{enumerate}

**Observación:** Es idóneo recordar que los criterios $\text{R}_{p}^{2}, \text{ MSE}_{p}$ permiten escoger modelos que ajusten bien a los datos, mientras que, por su parte, $C_{p}$ *de Mallows'* permite escoger el mejor modelo para predecir.

```{=html}
<!--
# References
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\vspace*{-0.2in}
\noindent
-->
```
